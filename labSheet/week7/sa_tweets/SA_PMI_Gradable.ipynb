{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter # Counter() is a dict for counting\n",
    "from collections import defaultdict\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment values\n",
    "sentiments = [\"positive\",\"neutral\",\"negative\"]\n",
    "# List of positive words:\n",
    "pos_words = [\"love\", \"great\", \"like\"]\n",
    "# List of negative words:\n",
    "neg_words = [\"hate\", \"bad\", \"annoy\"]\n",
    "# List of target companies:\n",
    "companies = [\"@virginamerica\", \"@united\", \"@southwestair\", \"@jetblue\", \"@usairways\", \"@americanair\"]\n",
    "sentiment_words = pos_words+neg_words\n",
    "\n",
    "def s2id(sentiment):\n",
    "    if sentiment == \"positive\":\n",
    "        return 0\n",
    "    elif sentiment == \"neutral\":\n",
    "        return 1\n",
    "    elif sentiment == \"negative\":\n",
    "        return 2\n",
    "    else:\n",
    "        print(\"ERROR: bad value!!\")\n",
    "        return -1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any counts from dictionary if it's below min_threshold or above max_treshold\n",
    "#max_threshold is ignored if unset\n",
    "def filter_occ_counts(counts, min_threshold, max_threshold=0):\n",
    "    if (max_threshold > 0):\n",
    "        return Counter({w : counts[w] for w in counts.keys() if counts[w] > min_threshold and counts[w] < max_threshold})\n",
    "    else:\n",
    "        return Counter({w : counts[w] for w in counts.keys() if counts[w] > min_threshold})\n",
    "\n",
    "#remove any co-occurence counts if below threshold \n",
    "def filter_cooc_counts(co_counts, min_threshold):\n",
    "     return {w: filter_occ_counts(co_counts[w], min_threshold) for w in co_counts.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: PMI is incorrectly defined\n"
     ]
    }
   ],
   "source": [
    "def PMI(c_xy, c_x, c_y, N):\n",
    "    # Computes PMI(x, y) where\n",
    "    # c_xy is the number of times x co-occurs with y\n",
    "    # c_x is the number of times x occurs.\n",
    "    # c_y is the number of times y occurs.\n",
    "    # N is the number of observations.\n",
    "    pmi = 0\n",
    "    #TODO: code the PMI here\n",
    "    return pmi;\n",
    "\n",
    "#Do a simple error check using value computed by hand\n",
    "if(PMI(2,4,3,12) != 1): # these numbers are from our y,z example\n",
    "    print(\"Warning: PMI is incorrectly defined\")\n",
    "else:\n",
    "    print(\"PMI check passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 0\n"
     ]
    }
   ],
   "source": [
    "# Define the data structures used to store the counts:\n",
    "occ_counts = Counter(); # Occurrence counts\n",
    "cooc_counts = defaultdict(Counter); # Co-occurrence counts:\n",
    "\n",
    "#This will be indexed by target words. cooc_counts[companies] will contain\n",
    "#a dictionary of co-occurrence counts of companies with each sentiment word.\n",
    "# read the file Tweets_short.csv\n",
    "df = pd.read_csv(\"Tweets_short.csv\", index_col=0)\n",
    "\n",
    "# TODO: apply preprocessing (e.g. lowercase)\n",
    "# TODO: update N so that it contains the total number of tweets\n",
    "N = 0\n",
    "print(\"Total number of tweets: {}\".format(N))\n",
    "\n",
    "#iterate over the tweets and count the words\n",
    "for sentiment, tweet in df.itertuples(index=False):\n",
    "    words = set(tweet.strip().split()) #remove duplicate words\n",
    "    for word in words:\n",
    "        occ_counts[word] += 1 # Store occurence counts for all words\n",
    "        # but only get co-occurrence counts for companies/sentiment word pairs\n",
    "        if word in companies:\n",
    "            for word2 in words:\n",
    "                if word2 in sentiment_words:\n",
    "                    cooc_counts[word][word2] += 1 # Store co-occurence counts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of positive words:\n",
      "[('like', 398), ('great', 193), ('love', 166)]\n",
      "Counts of negative words:\n",
      "[('bad', 127), ('hate', 33), ('annoy', 0)]\n",
      "Counts of company:\n",
      "[('@united', 3620), ('@usairways', 83), ('@jetblue', 45), ('@southwestair', 42), ('@americanair', 35), ('@virginamerica', 17)]\n",
      "\n",
      "@virginamerica cooc counts: [('like', 1)]\n",
      "@united        cooc counts: [('like', 107), ('great', 32), ('bad', 30), ('love', 20), ('hate', 9)]\n",
      "@southwestair  cooc counts: [('like', 2), ('great', 1)]\n",
      "@jetblue       cooc counts: [('love', 3), ('hate', 1), ('great', 1)]\n",
      "@usairways     cooc counts: [('great', 2), ('bad', 2), ('like', 2)]\n",
      "@americanair   cooc counts: [('like', 1)]\n"
     ]
    }
   ],
   "source": [
    "#For a Counter c, c.most_common(n) returns a sorted list of the n most common \n",
    "#items in c. If no n is given, it returns all items, sorted by decreasing frequency\n",
    "print(\"Counts of positive words:\")\n",
    "print(Counter({w : occ_counts[w] for w in pos_words}).most_common())\n",
    "print(\"Counts of negative words:\")\n",
    "print(Counter({w : occ_counts[w] for w in neg_words}).most_common())\n",
    "print(\"Counts of company:\")\n",
    "print(Counter({w : occ_counts[w] for w in companies}).most_common())\n",
    "print()\n",
    "for company in companies:\n",
    "    print(\"{:14s} cooc counts: {}\".format(company, cooc_counts[company].most_common()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@virginamerica:  0.00 (pos),   nan (neg)\n",
      "@united       :  0.00 (pos),  0.00 (neg)\n",
      "@southwestair :  0.00 (pos),   nan (neg)\n",
      "@jetblue      :  0.00 (pos),  0.00 (neg)\n",
      "@usairways    :  0.00 (pos),  0.00 (neg)\n",
      "@americanair  :  0.00 (pos),   nan (neg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loicbarrault/miniconda3/envs/nmtpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/loicbarrault/miniconda3/envs/nmtpy/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# TODO: filter out co-occurrences with too few counts **if you want**\n",
    "#cooc_counts = filter_cooc_counts(cooc_counts, 2)\n",
    "\n",
    "for company in companies:\n",
    "    company_count = occ_counts[company]\n",
    "    posPMIs = []\n",
    "    negPMIs = []\n",
    "    # TODO: compute PMI between company and each positive word, and\n",
    "    # add it to the list of positive sentiment PMI values\n",
    "\n",
    "    # TODO: same for negative sentiment words\n",
    "\n",
    "    # TODO: uncomment the following line when posPMIs and negPMIs are no longer empty.\n",
    "    #print(\"{:14s}: {:5.2f} (pos), {:5.2f} (neg)\".format((company).ljust(12), mean(posPMIs), mean(negPMIs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence = pd.read_csv(\"valence_lexicon_small.tsv\", sep='\\t', index_col=0)['Valence'].to_dict()\n",
    "\n",
    "with open(\"negation_words.txt\", 'rt') as fd:\n",
    "    negation_words = [line.rstrip() for line in fd]\n",
    "#print(negation_words)\n",
    "\n",
    "#See https://en.wiktionary.org/wiki/Category:English_degree_adverbs\n",
    "strengthen_words = pd.read_csv(\"strengthen_words.tsv\", sep='\\t', index_col=0)['score'].to_dict()\n",
    "#print(strengthen_words)\n",
    "\n",
    "weaken_words = pd.read_csv(\"weaken_words.tsv\", sep='\\t', index_col=0)['score'].to_dict()\n",
    "#print(weaken_words)\n",
    "\n",
    "exclamation_words = {'!':0.1, \"!!\":0.2, \"!!!\":0.3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradable method\n",
    "\n",
    "# This threshold is used to distinguish between negative / neutral / positive tweets\n",
    "# negative < -threshold <= neutral <= +threshold < positive\n",
    "threshold = 0.05\n",
    "cm = np.zeros((3,3))\n",
    "\n",
    "# TODO implement gradable method and compute confusion matrix and accuracy\n",
    "\n",
    "\n",
    "# TODO print results    \n",
    "print(\"######### TH = {}\".format(threshold))\n",
    "plot_confusion_matrix(cm           = cm, \n",
    "                      normalize    = False,\n",
    "                      target_names = sentiments,\n",
    "                      title        = \"Confusion Matrix\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
